.. _beforepushing:

Mandatory checks
================

.. contents:: Index
    :local:
    :depth: 2

Documentation
-------------

Each Pull Request should come with its own documentation updates, according to
what are the changes to be merged into master.

The documentation is generated by `Sphinx <https://www.sphinx-doc.org/en/master/>`__
with `reStructuredText <https://docutils.sourceforge.io/rst.html>`__ syntax.

To build and check your documentation locally,

- cd ``docs``
- for big changes (or just to be sure), ``rm api/* && make clean && make html``
- for small changes, ``make html``

The built documentation will be stored under ``docs/_build/html`` from which you
can open ``index.html`` with your favorite browser.

Please, try to fix any warning that could appear during documentation building.

.. warning::

  The Continuous Integration (CI) pipeline takes care of building the documentation
  once it is in master, but not for the Pull Request.

  Currently the documentation is built on GitHub Pages with Travis CI.
  There doesn't seem to be a way to see the documentation related to the PR
  online.

  For a next release, PR (:pr:`62`) will add the documentation also on
  `readthedocs <https://readthedocs.org/>`__ which allows this functionality.

Tests and unit-tests
--------------------

.. note::
  This is a maintenance activity which has being long overdue and we need
  manpower for it, so if you have experience on this or you want to contribute
  please feel free to do so.

Being *protopipe* based on *ctapipe*, all the tools imported from the latter
have been already tested and approved (remember that *protopipe* uses always the
latest version of *ctapipe* which has been released in the Anaconda framework).

.. warning::
  This is not true for,

  - hard-coded parts that had to be modified from ctapipe,
  - protopipe functions themselves (which will eventually migrate to ctapipe)

  Regarding the first point: given the difference in versions between the
  imported ctapipe and its development version, sometimes it's possible that, in
  order to code a new feature, this has to be pull-requested to ctapipe and at
  the same time hardcoded in protopipe, until the new version of ctapipe is released.

For the moment there is only one test, that is more than a unit-test.

This test is in charge to detect if changes in
`protopipe.pipeline.event_preparer` or `protopipe.scripts.write_dl1` produce any
fatal behaviour or crash.

It uses the `gamma_test_large` file of ctapipe (a Prod2 CTA South array composed of
LSTCam, FlashCam and ASTRICam with about ~100 simulated showers).
It is expected that an HDF5 file named `test_dl1.h5` is produced and is non-empty.

The test can be executed directly from the main folder of protopipe by launching
`pytest`. It is also automatically triggered by the continuous integration
everytime a new pull-request is pushed to the repository, and its correct
execution is a mandatory condition for merging.

.. warning::
  For the moment, in this test the shower images are not saved, so the
  correct production of the `images.h5` file is not automatically tested.

Benchmarks
----------

.. toctree::
   :hidden:

   benchmarks/TRAINING/benchmarks_DL1_calibration
   benchmarks/TRAINING/benchmarks_DL1_image-cleaning
   benchmarks/TRAINING/benchmarks_DL2_direction-reconstruction
   benchmarks/TRAINING/benchmarks_DL2_to_energy-estimation
   benchmarks/TRAINING/benchmarks_DL2_to_classification
   benchmarks/MODELS/benchmarks_MODELS_energy
   benchmarks/MODELS/benchmarks_MODELS_classification
   benchmarks/DL2/benchmarks_DL2_particle-classification
   benchmarks/DL2/benchmarks_DL2_direction-reconstruction
   benchmarks/DL3/benchmarks_DL3_cuts_optimization
   benchmarks/DL3/benchmarks_DL3_IRFs_and_sensitivity

This documentation hosts a series of notebooks used for benchmarking.

Their contents follow the development triggered by the ongoing
comparison between protopipe and CTA-MARS (see
`this issue <https://github.com/cta-observatory/protopipe/issues/24>`__ and
references therein for a summary).

Current simulated reference datasets used for the performance checks:

- Prod3b La Palma baseline zd=20deg az=180deg `(simtel files lists) <https://forge.in2p3.fr/attachments/download/63177/CTA-N_from_South.zip>`__

In the documentation we show only the actual results for immediate display.
You can find the details by opening the notebooks with ``jupyter lab``
from their location at ``docs/contribute/benchmarks``.

The benchmarks are organised as follows,

- TRAINING

  * `Calibration <benchmarks/TRAINING/benchmarks_DL1_calibration.ipynb>`__ | *benchmarks_DL1_calibration.ipynb*
  * `Image cleaning <benchmarks/TRAINING/benchmarks_DL1_image-cleaning.ipynb>`__ | *benchmarks_DL1_image-cleaning.ipynb*
  * `Direction reconstruction <benchmarks/TRAINING/benchmarks_DL2_direction-reconstruction.ipynb>`__ | *benchmarks_DL2_direction-reconstruction.ipynb*
  * `to energy estimator <benchmarks/TRAINING/benchmarks_DL2_to_energy-estimation.ipynb>`__ | *benchmarks_DL2_to_energy-estimation.ipynb*
  * `to classifier <benchmarks/TRAINING/benchmarks_DL2_to_classification.ipynb>`__ | *benchmarks_DL2_to_classification.ipynb*

This folder contains also some reference data from the CTAMARS pipeline.

- MODELS

These performances are obtained from a *test* portion of the TRAINING data,

  * `Energy <benchmarks/MODELS/benchmarks_MODELS_energy.ipynb>`__ | *benchmarks_MODELS_energy.ipynb*
  * `Particle type <benchmarks/MODELS/benchmarks_MODELS_classification.ipynb>`__ | *benchmarks_MODELS_classification.ipynb*

- DL2

  * `Particle classification <benchmarks/DL2/benchmarks_DL2_particle-classification.ipynb>`__ | *benchmarks_DL2_particle-classification.ipynb*
  * `Direction reconstruction <benchmarks/DL2/benchmarks_DL2_direction-reconstruction.ipynb>`__ | *benchmarks_DL2_direction-reconstruction.ipynb*


- DL3

  * `Cuts optimization <benchmarks/DL3/benchmarks_DL3_cuts_optimization.ipynb>`__ | *benchmarks_DL3_cuts_optimization.ipynb*
  * `Instrument Response Functions and sensitivity (internal) <https://forge.in2p3.fr/projects/benchmarks-reference-analysis/wiki/Protopipe_performance_data>`__ | *benchmarks_DL3_IRFs_and_sensitivity*

The DL3 folder contains also the CTA requirements, while the ASWG performance
data is left to the user, being internal.

.. note::
   This part of protopipe is not meant to be kept here in the end, in order to
   avoid divergences with
   `ctaplot <https://github.com/cta-observatory/ctaplot>`__ and
   `cta-benchmarks <https://github.com/cta-observatory/cta-benchmarks>`__.

.. note::
   The storage of static versions of the benchmarks in this documentation is temporary.
   It it is planned to run such benchmarks in the
   future via an external resource which will deal automatically with the
   pipeline code, the reference files and related output.

   For the moment the purpose of use these tools in the current setup is to help
   early developers and testers to check if their changes improve or degrade
   previous performances.
