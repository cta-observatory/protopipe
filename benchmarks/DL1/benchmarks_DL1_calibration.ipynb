{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author(s):**\n",
    " - Dr. Michele Peresano (CEA-Saclay/IRFU/DAp/LEPCHE), 2020\n",
    "\n",
    "**Description:**\n",
    "\n",
    "This notebook contains DL1-calibration plots and benchmark proposals for the _protopipe_ pipeline.  \n",
    "This was mainly triggered by the step-by-step comparison against _CTA-MARS_, but it can be extended to other pipelines as well.  \n",
    "**NOTE** Let's try to follow [this](https://www.overleaf.com/16933164ghbhvjtchknf) document by adding those benchmarks or proposing new ones.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "To run this notebook you will need an _images.h5_ file which can be generated using _write_dl1.py_ .  \n",
    "Reference simtel-file, plots, values and settings can be found [here (please, always refer to the latest version)](https://forge.in2p3.fr/projects/benchmarks-reference-analysis/wiki/Comparisons_between_pipelines) until we have a more automatic and fancy approach (aka [cta-benchmarks](https://github.com/cta-observatory/cta-benchmarks)+[ctaplot](https://github.com/cta-observatory/ctaplot)).  \n",
    "\n",
    "The data format required to run the notebook is the current one used by _protopipe_ . Later on it will be the same as in _ctapipe_ .  \n",
    "**WARNING:** Mono-telescope images (2 triggers - 1 image or 1 trigger - 1 image) are not currently taken into account by the publicly available development version (the new DL1 script will have them automatically, so I decided to skip this feature in protopipe), until then expect a somewhat lower statistics.\n",
    "\n",
    "**Development and testing:**  \n",
    "\n",
    "For the moment this notebook is optimized to work only on files produced from LSTCam + NectarCam telescope configurations.  \n",
    "As with any other part of _protopipe_ and being part of the official repository, this notebook can be further developed by any interested contributor.  \n",
    "The execution of this notebook is not currently automatic, it must be done locally by the user - preferably _before_ pushing a pull-request.  \n",
    "**IMPORTANT:** Please, if you wish to contribute to this notebook, before pushing anything to your branch (better even before opening the PR) clear all the output and remove any local directory paths that you used for testing (leave empty strings). The file used should always be _gamma_20deg_180deg_run100___cta-prod3-demo-2147m-LaPalma-baseline.simtel.gz_ until Prod5.\n",
    "\n",
    "**TODO:**  \n",
    "* manage all cameras depending on input data\n",
    "* decide what to do with calibScale (either move to code, or remove altogether)\n",
    "* update input data whith ctapipe 0.8 is released (DL1 data format frozen)\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import percentileofscore\n",
    "import tables\n",
    "import uproot\n",
    "from astropy.io import ascii\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from ctapipe.io import event_source\n",
    "from ctapipe.instrument import CameraGeometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add statistical information to a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stats(data, ax, x = 0.70, y = 0.85, color = \"black\"):\n",
    "    \"\"\"Add a textbox containing statistical information.\"\"\"\n",
    "    mu = data.mean()\n",
    "    median = np.median(data)\n",
    "    sigma = data.std()\n",
    "    textstr = '\\n'.join((\n",
    "        r'$\\mu=%.2f$' % (mu, ),\n",
    "        r'$\\mathrm{median}=%.2f$' % (median, ),\n",
    "        r'$\\sigma=%.2f$' % (sigma, )))\n",
    "\n",
    "    # these are matplotlib.patch.Patch properties\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "\n",
    "    # place a text box in upper left in axes coords\n",
    "    ax.text(x, y, \n",
    "            textstr, \n",
    "            transform=ax.transAxes, \n",
    "            fontsize=10,\n",
    "            horizontalalignment='left',\n",
    "            verticalalignment='center', \n",
    "            bbox=props,\n",
    "            color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral weight from requirement B-TEL-1010 \"Intensity Resolution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_weight_BTEL1010(tel_data):\n",
    "    \"\"\"Define the weights from requirement B-TEL-1010-Intensity Resolution.\"\"\"\n",
    "    target_slope = -2.62 # this is the spectral slope as required by the B-TEL-1010 \"Intensity Resolution\" doc\n",
    "    spec_slope = -2.0 # this is the spectral slope in the simtel files\n",
    "    energies = tel_data.col(\"mc_energy\")*1.e3 # GeV\n",
    "    # each image array needs the same weight\n",
    "    weights = np.repeat(np.power(energies/200., target_slope - spec_slope), 1855)\n",
    "    return weights.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of the bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bias(x_bin_edges, y_bin_edges, hist):\n",
    "    \"\"\"Calculate the average bias of charge resolution from 50 to 500 true photoeletrons.\n",
    "    These limits are chosen in order to be safely away from saturation and from NSB noise.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_bin_edges : 1D array\n",
    "        Bin edges in true photoelectrons.\n",
    "    y_bin_edges : 1D array\n",
    "        Bin edges in reconstructed/true photoelectrons.\n",
    "    hist : 2D array\n",
    "        The full histogram of reconstructed/true against true photoelectrons.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    bias : float\n",
    "        Average bias of charge resolution from 50 to 500 true photoelectrons.\n",
    "    \n",
    "    \"\"\"\n",
    "    min_edge_index = np.digitize(1.7, x_bin_edges) - 1\n",
    "    max_edge_index = np.digitize(2.7, x_bin_edges)\n",
    "\n",
    "    proj = np.zeros(600)\n",
    "    for i in range(min_edge_index, max_edge_index + 1):\n",
    "        proj = proj + hist[i]\n",
    "\n",
    "    y_bin_centers = 0.5*(y_bin_edges[1:] + y_bin_edges[:-1])\n",
    "\n",
    "    bias = 1./np.average(y_bin_centers, weights = proj)\n",
    "    \n",
    "    return bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Square around 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rms(values, weights):\n",
    "    \"\"\"Root Mean Square around 1 as proposed from comparison with CTA-MARS.\n",
    "    \n",
    "    The input values are vertical slices of the 2D histogram showing the bias-corrected charge resolution.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    values : 1D array\n",
    "        Values in reconstructed / true photoelectrons corrected for average bias.\n",
    "    weights : 1D array\n",
    "        Counts in a cell from the weigthed histogram.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    rms : float\n",
    "        Root Mean Square of around 1 for a vertical slice.\n",
    "    \n",
    "    \"\"\"\n",
    "    average = np.average(values, weights=weights)\n",
    "    variance = np.average((values-average)**2, weights=weights)\n",
    "    standard_deviation = np.sqrt(variance)\n",
    "    a = np.power(standard_deviation,2)\n",
    "    b = np.power(average-1,2)\n",
    "    rms = np.sqrt(a+b)\n",
    "    return rms\n",
    "\n",
    "# missing errors (err_rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the base data file or reset it if overwritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reset_simtel(indir = \"./\", fileName = \"gamma_20deg_180deg_run100___cta-prod3-demo-2147m-LaPalma-baseline.simtel.gz\", max_events=None, config=\"test\"):\n",
    "    \"\"\"(Re)load the simtel file for all events and telescopes.\"\"\"\n",
    "    source = event_source(input_url=f\"{indir}/{fileName}\", max_events=max_events)\n",
    "    suffix = config # all generated plots will have this as a suffix in their name\n",
    "    return source, suffix\n",
    "\n",
    "def load_reset_images(indir = \"./\", fileName = \"images.h5\", config=\"test\"):\n",
    "    \"\"\"(Re)load the file containing the images and extract the data per telescope type.\"\"\"\n",
    "    # load DL1 images\n",
    "    data = tables.open_file(f\"{indir}/{fileName}\")\n",
    "    data_LST = data.get_node(\"/images_LSTCam\")\n",
    "    data_MST = data.get_node(\"/images_NectarCam\")\n",
    "    suffix = config # all generated plots will have this as a suffix in their name\n",
    "    return data_LST, data_MST, suffix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we check if a _plots_ folder exists already.  \n",
    "If not, we create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"./plots_calibration\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B-TEL-1010 (converted in photolectrons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** this requirement takes into account Poissonian fluctuations, which in turn are not taken into account in this version of the benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photons = np.array([4.08996, 4.27598 , 4.47047 , 4.67381 , 4.88639 , 5.10864 , 5.341   , 5.58393 , 5.83791 , 6.10344 , 6.38105 , 6.67128 , 6.97472 , 7.29196 , 7.62362 , 7.97038 , 8.3329  , 8.71191 , 9.10816 , 9.52244 , 9.95555 , 10.4084 , 10.8818 , 11.3767 , 11.8942 , 12.4352 , 13.0008 , 13.5921 , 14.2103 , 14.8567 , 15.5324 , 16.2389 , 16.9775 , 17.7497 , 18.557  , 19.4011 , 20.2835 , 21.2061 , 22.1706 , 23.179  , 24.2333 , 25.3355 , 26.4879 , 27.6926 , 28.9522 , 30.2691 , 31.6458 , 33.0852 , 34.59   , 36.1633 , 37.8082 , 39.5278 , 41.3257 , 43.2054 , 45.1705 , 47.225  , 49.373  , 51.6187 , 53.9665 , 56.4211 , 58.9874 , 61.6704 , 64.4754 , 67.4079 , 70.4739 , 73.6793 , 77.0306 , 80.5342 , 84.1972 , 88.0268 , 92.0306 , 96.2166 , 100.593 , 105.168 , 109.952 , 114.953 , 120.181 , 125.648 , 131.362 , 137.337 , 143.584 , 150.115 , 156.943 , 164.081 , 171.544 , 179.346 , 187.504 , 196.032 , 204.948 , 214.27  , 224.016 , 234.205 , 244.858 , 255.995 , 267.639 , 279.812 , 292.539 , 305.844 , 319.755 , 334.299 , 349.504 , 365.401 , 382.021 , 399.397 , 417.563 , 436.555 , 456.412 , 477.171 , 498.875 , 521.565 , 545.288 , 570.09  , 596.02  , 623.129 , 651.472 , 681.103 , 712.082 , 744.47  , 778.332 , 813.733 , 850.745 , 889.44  , 929.896 , 972.191 , 1016.41 , 1062.64 , 1110.97 , 1161.5  , 1214.33 , 1269.57 , 1327.31 , 1387.68 , 1450.8  , 1516.79 , 1585.78 , 1657.9  , 1733.31 , 1812.15 , 1894.57 , 1980.75 , 2070.84 , 2165.03 , 2263.5  , 2366.46 , 2474.09 , 2586.62 , 2704.27 , 2827.27 , 2955.87 , 3090.31 , 3230.87 , 3377.82 , 3531.46 , 3692.09 , 3860.02 , 4035.58])\n",
    "req = np.array([1.98387, 1.91316, 1.84541, 1.78049, 1.71827, 1.65863, 1.60145, 1.54663, 1.49407, 1.44366, 1.3953, 1.34892, 1.30441, 1.26169, 1.22069, 1.18133, 1.14354, 1.10725, 1.07238, 1.03889, 1.0067, 0.975761, 0.946017, 0.917414, 0.889904, 0.863438, 0.83797, 0.813457, 0.789858, 0.767131, 0.745241, 0.72415, 0.703825, 0.684233, 0.665342, 0.647122, 0.629546, 0.612586, 0.596217, 0.580413, 0.565152, 0.550412, 0.53617, 0.522407, 0.509103, 0.49624, 0.483801, 0.471769, 0.460128, 0.448862, 0.437958, 0.427401, 0.417179, 0.407278, 0.397688, 0.388395, 0.379391, 0.370664, 0.362204, 0.354003, 0.34605, 0.338337, 0.330857, 0.323601, 0.316561, 0.309732, 0.303104, 0.296673, 0.290432, 0.284375, 0.278496, 0.272789, 0.267249, 0.261872, 0.256651, 0.251584, 0.246664, 0.241888, 0.237252, 0.232751, 0.228382, 0.224141, 0.220025, 0.21603, 0.212152, 0.208389, 0.204737, 0.201193, 0.197755, 0.19442, 0.191185, 0.188047, 0.185003, 0.182052, 0.179191, 0.176417, 0.173729, 0.171124, 0.168599, 0.166153, 0.163784, 0.16149, 0.159268, 0.157117, 0.155035, 0.15302, 0.151071, 0.149185, 0.147361, 0.145597, 0.143892, 0.142244, 0.140651, 0.139112, 0.137625, 0.13619, 0.134804, 0.133465, 0.132174, 0.130928, 0.129726, 0.128566, 0.127448, 0.12637, 0.125331, 0.124329, 0.123364, 0.122435, 0.12154, 0.120678, 0.119848, 0.119049, 0.11828, 0.117541, 0.116829, 0.116145, 0.115487, 0.114854, 0.114245, 0.113661, 0.113099, 0.112559, 0.11204, 0.111542, 0.111063, 0.110604, 0.110162, 0.109739, 0.109332, 0.108942, 0.108567, 0.108208, 0.107863, 0.107532, 0.107215, 0.106911])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MonteCarlo data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT Basic information about the reference simtel file**  \n",
    "The file used in these benchmarks is  \n",
    "_gamma_20deg_180deg_run100___cta-prod3-demo-2147m-LaPalma-baseline.simtel.gz_  \n",
    "and has the following basic features when NO selection is applied,\n",
    "* number of simulated showers  = 9793\n",
    "* number of images (LST + MST) = 44401\n",
    "* min number of triggered telescopes per shower = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load every time you want to plot simtel-related information....\n",
    "indir = \"\" # path of the reference simtel file in your setup\n",
    "infile = \"gamma_20deg_180deg_run100___cta-prod3-demo-2147m-LaPalma-baseline.simtel.gz\"\n",
    "source, config = load_reset_simtel(indir=indir,\n",
    "                                   fileName=infile,\n",
    "                                  max_events=2, # 2nd event is 1st to trigger both cameras\n",
    "                                  config=\"test\") # suffix for the plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protopipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill with the your path, filename of the generated file in your system + config name\n",
    "data_LST, data_MST, config = load_reset_images(indir=\"\",  # path of the images file in your setup\n",
    "                                               fileName=\"images.h5\",\n",
    "                                               config=\"test\") # suffix for the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_images = 44401 - len(data_LST.col(\"mc_phe_image\")) - len(data_MST.col(\"mc_phe_image\"))\n",
    "if missing_images:\n",
    "    print(f\"WARNING: it appears you are missing {missing_images} images!\")\n",
    "    print(f\"This corresponds to about {missing_images*100/44401:.0f}% of the total statistics.\")\n",
    "    print(\"Please, check that:\")\n",
    "    print(\"* either you have enabled some cuts in analysis.yaml,\")\n",
    "    print(\"* or you are not considering some events in your analysis when you write to file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTA-MARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = \"\" # to be added, for the moment you can diable the related plots\n",
    "fileName = \"CTA_check_dl1a.root\"\n",
    "path_mars_hists = f\"{indir}/{fileName}\"\n",
    "\n",
    "fileName = \"IntensityResolution_graphs.root\"\n",
    "path_mars_rms = f\"{indir}/{fileName}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### protopipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** for the moment we do these checks only with LSTCam and NectarCam, but this notebook will be applied to all cameras eventually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibScale is placed here momentaneously\n",
    "calibscale = 0.92\n",
    "\n",
    "# LSTCam\n",
    "mc_lst = data_LST.col(\"mc_phe_image\").ravel()\n",
    "dl1_lst = data_LST.col(\"dl1_phe_image_1stPass\").ravel() / calibscale\n",
    "calibration_status_lst = np.repeat(data_LST.col(\"calibration_status\"),1855).ravel()\n",
    "dl1_2ndPass_lst = data_LST.col(\"dl1_phe_image\").ravel() / calibscale\n",
    "weights_lst = apply_weight_BTEL1010(data_LST)\n",
    "# NectarCam\n",
    "mc_mst = data_MST.col(\"mc_phe_image\").ravel()\n",
    "dl1_mst = data_MST.col(\"dl1_phe_image_1stPass\").ravel() / calibscale\n",
    "calibration_status_mst = np.repeat(data_MST.col(\"calibration_status\"),1855).ravel()\n",
    "dl1_2ndPass_mst = data_MST.col(\"dl1_phe_image\").ravel() / calibscale\n",
    "weights_mst = apply_weight_BTEL1010(data_MST)\n",
    "# Group\n",
    "mc_all = [mc_lst, mc_mst]\n",
    "reco_all = [dl1_lst, dl1_mst]\n",
    "reco_2ndPass_all = [dl1_2ndPass_lst, dl1_2ndPass_mst]\n",
    "weights_all = [weights_lst, weights_mst]\n",
    "calibration_status_all = [calibration_status_lst, calibration_status_mst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of pixel-wise values read from simtel file without cuts\")\n",
    "print(f\"LSTCam = {len(mc_all[0])}\")\n",
    "print(f\"NectarCam = {len(mc_all[1])}\")\n",
    "print(f\"'pixel-wise values' means #pixels * #cameras * #events\")\n",
    "print(f\"In this phase all single-telescope images are considered.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTA-MARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from CTA_check_dl1a.root\n",
    "file_hists = uproot.open(path_mars_hists)\n",
    "hist2 = file_hists[\"hist2_type00\"]\n",
    "H2 = hist2.numpy()\n",
    "# from IntensityResolution_graphs\n",
    "file_rms = uproot.open(path_mars_rms)\n",
    "rms_lst = file_rms[\"IntensityResolution_LST\"]\n",
    "rms_mst = file_rms[\"IntensityResolution_MST\"]\n",
    "rms = [rms_lst, rms_mst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R1-level information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pedestals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in source:\n",
    "    triggered_telescopes = np.asarray(list(event.r0.tels_with_data))\n",
    "    if (triggered_telescopes > 5).any() and (triggered_telescopes < 5).any():\n",
    "        lst_found = 0\n",
    "        for tel_id in triggered_telescopes:\n",
    "            cam_id = event.inst.subarray.tel[tel_id].camera.cam_id\n",
    "            pix_ids = event.inst.subarray.tel[tel_id].camera.pix_id\n",
    "            pedestals = event.mc.tel[tel_id].pedestal\n",
    "            if (lst_found == 1) and (cam_id == \"LSTCam\"):\n",
    "                continue\n",
    "            elif (lst_found == 0) and (cam_id == \"LSTCam\"):\n",
    "                fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12, 5), tight_layout=False, sharey=True)\n",
    "                ax1.set_xlabel(\"Pixel ID\")\n",
    "                ax1.set_ylabel(\"Pedestal ADC counts\")\n",
    "                p1 = ax1.plot(pix_ids, pedestals[1], label=\"High gain\")\n",
    "                p2 = ax1.plot(pix_ids, pedestals[0], label=\"Low gain\")\n",
    "                ax2.hist(pedestals[1], bins = 100, orientation=\"horizontal\", label=\"pedestals HG\")\n",
    "                add_stats(pedestals[1], ax2, x = 0.55, y = 0.10, color = p1[0].get_color())\n",
    "                ax2.hist(pedestals[0], bins = 100, orientation=\"horizontal\", label=\"pedestals LG\")\n",
    "                add_stats(pedestals[0], ax2, x = 0.55, y = 0.25, color = p2[0].get_color())\n",
    "                ax1.legend()\n",
    "                ax2.legend()\n",
    "                lst_found = 1\n",
    "                fig.savefig(f\"./plots_calibration/pedestalsVSpixelids_{cam_id}_protopipe_{config}.png\")\n",
    "            elif (lst_found == 1) and (cam_id == \"NectarCam\"):\n",
    "                fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12, 5), tight_layout=False, sharey=True)\n",
    "                ax1.set_xlabel(\"Pixel ID\")\n",
    "                ax1.set_ylabel(\"Pedestal ADC counts\")\n",
    "                p1 = ax1.plot(pix_ids, pedestals[1], label=\"High gain\")\n",
    "                p2 = ax1.plot(pix_ids, pedestals[0], label=\"Low gain\")\n",
    "                ax2.hist(pedestals[1], bins = 100, orientation=\"horizontal\", label=\"pedestals HG\")\n",
    "                add_stats(pedestals[1], ax2, x = 0.55, y = 0.10, color = p1[0].get_color())\n",
    "                ax2.hist(pedestals[0], bins = 100, orientation=\"horizontal\", label=\"pedestals LG\")\n",
    "                add_stats(pedestals[0], ax2, x = 0.55, y = 0.25, color = p2[0].get_color())\n",
    "                ax1.legend()\n",
    "                ax2.legend()\n",
    "                fig.savefig(f\"./plots_calibration/pedestalsVSpixelids_{cam_id}_protopipe_{config}.png\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DC to PHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no cycle over events since we already have a good event from the previous cell\n",
    "triggered_telescopes = np.asarray(list(event.r0.tels_with_data))\n",
    "if (triggered_telescopes > 5).any() and (triggered_telescopes < 5).any():\n",
    "    lst_found = 0\n",
    "    for tel_id in triggered_telescopes:\n",
    "        cam_id = event.inst.subarray.tel[tel_id].camera.cam_id\n",
    "        pix_ids = event.inst.subarray.tel[tel_id].camera.pix_id\n",
    "        dc_to_pe = event.mc.tel[tel_id].dc_to_pe\n",
    "        if (lst_found == 1) and (cam_id == \"LSTCam\"):\n",
    "            continue\n",
    "        elif (lst_found == 0) and (cam_id == \"LSTCam\"):\n",
    "            lst_found = 1\n",
    "            dc_to_pe_channels_lst = dc_to_pe\n",
    "        elif (lst_found == 1) and (cam_id == \"NectarCam\"):\n",
    "            dc_to_pe_channels_mst = dc_to_pe\n",
    "            break\n",
    "# plot channel-wise\n",
    "for i, gain in enumerate([\"High\", \"Low\"]):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12, 5), tight_layout=False, sharey=True)\n",
    "    ax1.set_xlabel(\"Pixel ID\")\n",
    "    ax2.set_ylabel(f\"DC to PHE - {gain} gain\")\n",
    "    p1 = ax1.plot(pix_ids, dc_to_pe_channels_lst[i], label=\"LSTCam\")\n",
    "    p2 = ax1.plot(pix_ids, dc_to_pe_channels_mst[i], label=\"NectarCam\")\n",
    "    ax2.hist(dc_to_pe_channels_lst[i], bins = 100, orientation=\"horizontal\", label=\"pedestals HG\")\n",
    "    add_stats(dc_to_pe_channels_lst[i], ax2, x = 0.55, y = 0.30, color = p1[0].get_color())\n",
    "    ax2.hist(dc_to_pe_channels_mst[i], bins = 100, orientation=\"horizontal\", label=\"pedestals LG\")\n",
    "    add_stats(dc_to_pe_channels_mst[i], ax2, x = 0.55, y = 0.55, color = p2[0].get_color())\n",
    "    ax1.legend()\n",
    "    ax2.legend()\n",
    "    fig.savefig(f\"./plots_calibration/dcTophe{gain}GainVSpixelids_LSTCam+NectarCam_protopipe_{config}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between the reconstructed and true number of photoelectrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter positive number of photoelectrons (because it's a log-log plot)\n",
    "good_values_mst = np.where((mc_mst>0) & (dl1_mst>0))\n",
    "good_values_lst = np.where((mc_lst>0) & (dl1_lst>0))\n",
    "# combine cameras\n",
    "mc = [mc_lst[good_values_lst], mc_mst[good_values_mst]]\n",
    "reco = [dl1_lst[good_values_lst], dl1_mst[good_values_mst]]\n",
    "# filter also weights\n",
    "weights = [weights_lst[good_values_lst], weights_mst[good_values_mst]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins_x = 400\n",
    "nbins_y = 400\n",
    "cameras = [\"LSTCam\", \"NectarCam\"] # this could go up, where data is loaded so in the future it reads automaically\n",
    "\n",
    "for camera_index in range(len(cameras)):\n",
    "    fig = plt.figure(figsize=(6, 5), tight_layout=False)\n",
    "    \n",
    "    plt.title(cameras[camera_index])\n",
    "    plt.xlabel(\"log10(true #p.e)\")\n",
    "    plt.ylabel(\"log10(reco #p.e)\")\n",
    "    \n",
    "    # This is just to count the real number of events given to the histogram\n",
    "    h_no_weights = plt.hist2d(np.log10(mc[camera_index]), np.log10(reco[camera_index]),\n",
    "                   bins=[nbins_x, nbins_y],\n",
    "                   range=[[-7.,5.],[-7.,5.]],\n",
    "                   norm=LogNorm(),\n",
    "                  )\n",
    "    \n",
    "    # This histogram has the weights applied, so the number of events there is biased by this\n",
    "    # This is what is plot\n",
    "    h = plt.hist2d(np.log10(mc[camera_index]), np.log10(reco[camera_index]),\n",
    "                   bins=[nbins_x, nbins_y],\n",
    "                   range=[[-7.,5.],[-7.,5.]],\n",
    "                   norm=LogNorm(),\n",
    "                   cmap=plt.cm.rainbow,\n",
    "                   weights=weights[camera_index],\n",
    "                  )\n",
    "    \n",
    "    plt.plot([0, 4], [0, 4], color=\"black\") # line showing perfect correlation\n",
    "    plt.minorticks_on()\n",
    "    plt.xticks(ticks=np.arange(-1, 5, 0.5), labels=[\"\",\"\"]+[str(i) for i in np.arange(0, 5, 0.5)])\n",
    "    plt.xlim(-0.2,4.2)\n",
    "    plt.ylim(-4.,4.)\n",
    "    plt.colorbar(h[3], \n",
    "                 ax=plt.gca()\n",
    "                )\n",
    "    plt.grid()\n",
    "    \n",
    "    fig.savefig(f\"./plots_calibration/recoPhesVsTruePhes_{cameras[camera_index]}_protopipe_{config}.png\")\n",
    "    \n",
    "    # Print some debug/benchmarking information\n",
    "    print(f\"Total number of events in the plot of {cameras[camera_index]} (before re-weighting) = {h_no_weights[0].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charge resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First restore reconstructed negative values, since now we take ratios, instead of logarithms\n",
    "# filter only positive number of true photoelectrons\n",
    "good_values_lst = np.where(mc_all[0]>0)\n",
    "good_values_mst = np.where(mc_all[1]>0)\n",
    "# combine cameras\n",
    "mc = [mc_all[0][good_values_lst], mc_all[1][good_values_mst]]\n",
    "reco = [reco_all[0][good_values_lst], reco_all[1][good_values_mst]]\n",
    "weights = [weights_all[0][good_values_lst], weights_all[1][good_values_mst]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins_x = 800\n",
    "nbins_y = 600\n",
    "\n",
    "histogram = [] # camera-wise un-zoomes histogram for calculating bias later on\n",
    "\n",
    "for camera_index in range(len(cameras)):\n",
    "    \n",
    "    fig = plt.figure(figsize=(6, 5), tight_layout=False)\n",
    "    \n",
    "    plt.title(cameras[camera_index])\n",
    "    plt.xlabel(\"log10(true #p.e)\")\n",
    "    plt.ylabel(\"reconstructed #p.e / true #p.e\")\n",
    "    \n",
    "    h = plt.hist2d(np.log10(mc[camera_index]), (reco[camera_index]/mc[camera_index]),\n",
    "                   bins=[nbins_x, nbins_y],\n",
    "                   range=[[-7.,15.],[-2,13]],\n",
    "                   norm=LogNorm(),\n",
    "                   cmap=plt.cm.rainbow,\n",
    "                   weights=weights[camera_index],\n",
    "                  )\n",
    "    \n",
    "    histogram.append(h)\n",
    "    \n",
    "    plt.plot([0, 4], [1, 1], color=\"black\") # line showing perfect correlation\n",
    "    plt.colorbar(h[3], ax=plt.gca()\n",
    "                 #, format=ticker.FuncFormatter(fmt)\n",
    "                )\n",
    "    ax = plt.gca()\n",
    "    ax.minorticks_on()\n",
    "    ax.tick_params(axis='x', which='minor')\n",
    "    plt.grid()\n",
    "    plt.xlim(-0.2,4.2)\n",
    "    plt.ylim(-2.,6.)\n",
    "\n",
    "    fig.savefig(f\"./plots_calibration/chargeResolution_1stPass_{cameras[camera_index]}_protopipe_{config}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of the average bias for each camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = []\n",
    "print(f\"Correction factors for average bias : \")\n",
    "for camera_index in range(len(cameras)):\n",
    "    corr.append(calc_bias(histogram[camera_index][1], histogram[camera_index][2], histogram[camera_index][0]))\n",
    "    print(f\"- {cameras[camera_index]} = {corr[camera_index]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charge resolution corrected for average bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins_x = 800\n",
    "nbins_y = 600\n",
    "\n",
    "histogram = [] # camera-wise un-zoomes histogram for calculating RMS later on\n",
    "\n",
    "for camera_index in range(len(cameras)):\n",
    "    \n",
    "    fig = plt.figure(figsize=(6, 5), tight_layout=False)\n",
    "    \n",
    "    plt.title(cameras[camera_index])\n",
    "    plt.xlabel(\"log10(true #p.e)\")\n",
    "    plt.ylabel(\"{:.2f}*(reconstructed #p.e / true #p.e)\".format(corr[camera_index]))\n",
    "    \n",
    "    h = plt.hist2d(np.log10(mc[camera_index]), corr[camera_index]*(reco[camera_index]/mc[camera_index]),\n",
    "                   bins=[nbins_x, nbins_y],\n",
    "                   range=[[-7.,15.],[-2,13]],\n",
    "                   norm=LogNorm(),\n",
    "                   cmap=plt.cm.rainbow,\n",
    "                   weights=weights[camera_index],\n",
    "                  )\n",
    "    \n",
    "    histogram.append(h)\n",
    "    \n",
    "    plt.plot([0, 4], [1, 1], color=\"black\") # line showing perfect correlation\n",
    "    plt.colorbar(h[3], ax=plt.gca()\n",
    "                 #, format=ticker.FuncFormatter(fmt)\n",
    "                )\n",
    "    ax = plt.gca()\n",
    "    ax.minorticks_on()\n",
    "    ax.tick_params(axis='x', which='minor')\n",
    "    plt.grid()\n",
    "    plt.xlim(-0.2,4.2)\n",
    "    plt.ylim(-2.,6.)\n",
    "\n",
    "    fig.savefig(f\"./plots_calibration/chargeResolution_1stPass_{cameras[camera_index]}_protopipe_{config}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMS of charge resolution (around 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for camera_index in range(len(cameras)):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,5), tight_layout=False)\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "\n",
    "    bin_edges_true = histogram[camera_index][1]\n",
    "    bincenters_true = 0.5*(bin_edges_true[1:]+bin_edges_true[:-1]) # mean value of each bin in true photoelectrons\n",
    "    bin_edges_y = histogram[camera_index][2] # bin edges in reconstructed photoelectrons\n",
    "    bincenters_y = 0.5*(bin_edges_y[1:]+bin_edges_y[:-1]) # mean value of each bin in reconstructed photoelectrons\n",
    "\n",
    "    # cycle over bins in true photoelectrons:\n",
    "    values = []\n",
    "    errors = []\n",
    "    n = 0\n",
    "    ref = []\n",
    "    for true_bin in range(len(bincenters_true)):\n",
    "        # if the bin center is over 3.2\n",
    "        if (bincenters_true[true_bin] > 3.2):\n",
    "            break # stop\n",
    "        # if it's before -0.5\n",
    "        if (bincenters_true[true_bin] < -0.5):\n",
    "            continue # check the next bin\n",
    "        # else proceed with the calculation\n",
    "        # take the profile at this X bin along the Y axis\n",
    "        profile_y = histogram[camera_index][0][true_bin] # this is the sequence of weights (aka the heights of the 600 bins)\n",
    "        # if there is data falling in this X-axis bin,\n",
    "        if np.sum(profile_y):\n",
    "            ref.append(true_bin)\n",
    "            # get the resolution the way Abelardo does\n",
    "            # to do this we need also the bin centers along the Y axis\n",
    "            result = calc_rms(bincenters_y, profile_y)\n",
    "            values.append(result)\n",
    "\n",
    "            # error bars TO DO\n",
    "\n",
    "            n = n + 1\n",
    "        else: # otherwise go to the next bin in true photoelectrons\n",
    "            continue\n",
    "\n",
    "    values = np.asarray(values)\n",
    "    # errors = np.asarray(errors)\n",
    "\n",
    "    # protopipe\n",
    "    plt.plot(bincenters_true[ref], values, 'o', markersize=2, label=\"protopipe\")\n",
    "    # plt.errorbar(bincenters_true[ref], values, yerr=errors, fmt='o',markersize=2, label=\"protopipe\")\n",
    "    \n",
    "    # CTA-MARS\n",
    "    rms[camera_index].matplotlib(fmt=\"o\", markersize=2, label=\"CTA-MARS\")\n",
    "\n",
    "    plt.yscale(\"log\")\n",
    "    plt.ylim(0.02,6)\n",
    "    plt.xlim(-0.2,4.2)\n",
    "\n",
    "    # superimose requirement converted in p.e. from abelardo script\n",
    "    plt.plot(np.log10(photons), req, label=\"requirement\")\n",
    "\n",
    "    plt.grid(which='both', axis='y')\n",
    "    plt.grid(which='major', axis='x')\n",
    "    plt.minorticks_on()\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.title(cameras[camera_index])\n",
    "    plt.xlabel(\"log10(true #p.e)\")\n",
    "    plt.ylabel(\"Bias-corrected charge resolution RMS around 1\")\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    \n",
    "    plt.plot(rms[camera_index].xvalues, values/rms[camera_index].yvalues, label=\"ratio protopipe/CTA-MARS\")\n",
    "    ax = plt.gca()\n",
    "    xlims=ax.get_xlim()\n",
    "    plt.hlines(1., xlims[0], xlims[1], label=\"expectation\", color='r')\n",
    "    plt.ylim(0, 2)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"log10(true #p.e)\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** the requirement is placed only for completness, but it's not directly comparable to the data - see the *Requirements* section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-pixel spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter positive number of photoelectrons (for log-log plots)\n",
    "# good_values_lst_1stPass = np.where((mc_all[0]>0) & (reco_all[0]>0))\n",
    "# good_values_mst_1stPass = np.where((mc_all[1]>0) & (reco_all[1]>0))\n",
    "good_values_lst_1stPass = np.where(reco_all[0]>0)\n",
    "good_values_mst_1stPass = np.where(reco_all[1]>0)\n",
    "# 2nd pass also needs the 'calibration_status' variable\n",
    "# if 0 the image didn't survive the preliminary cleaning and the 2nd pass is null\n",
    "# good_values_lst_2ndPass = np.where((mc_all[0]>0) & (reco_2ndPass_all[0]>0) & (calibration_status_lst == 1))\n",
    "# good_values_mst_2ndPass = np.where((mc_all[1]>0) & (reco_2ndPass_all[1]>0) & (calibration_status_mst == 1))\n",
    "good_values_lst_2ndPass = np.where((reco_2ndPass_all[0]>0) & (calibration_status_lst == 1))\n",
    "good_values_mst_2ndPass = np.where((reco_2ndPass_all[1]>0) & (calibration_status_mst == 1))\n",
    "# combine cameras\n",
    "# mc_1stPass = [mc_all[0][good_values_lst_1stPass], mc_all[1][good_values_mst_1stPass]]\n",
    "# mc_2ndPass = [mc_all[0][good_values_lst_2ndPass], mc_all[1][good_values_mst_2ndPass]]\n",
    "reco_1stPass = [reco_all[0][good_values_lst_1stPass], reco_all[1][good_values_mst_1stPass]]\n",
    "reco_2ndPass = [reco_2ndPass_all[0][good_values_lst_2ndPass], reco_2ndPass_all[1][good_values_mst_2ndPass]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 250\n",
    "xrange = [-1,4]\n",
    "\n",
    "core_thresholds = []\n",
    "\n",
    "for camera_index in range(len(cameras)):\n",
    "    \n",
    "    fig = plt.figure(figsize=(6, 5), tight_layout=False)\n",
    "    \n",
    "    plt.title(cameras[camera_index])\n",
    "    plt.xlabel(\"log10(reconstructed #p.e)\")\n",
    "    plt.ylabel(\"Number of pixels with > x phe\")\n",
    "\n",
    "    # all the original simulated events\n",
    "    t = mc_all[camera_index]\n",
    "    tot_entries = len(t) # events * telescopes * pixels\n",
    "    # 1st pass: no cut, all 1st pass images are saved by the image extractor TwoPassWindowSum\n",
    "    # 2nd pass: only images which survived 1st pass and which preliminary image fit was non-patological\n",
    "    t_2ndPass = t[np.where((reco_2ndPass_all[camera_index]>0) & (calibration_status_all[camera_index] == 1))]\n",
    "    \n",
    "    # Since we are working only with simulated data,\n",
    "    # \"signal\" is when a pixel has at least 1 simulated photoelectron\n",
    "    # \"noise\"  is when a pixel has no simulated photoelectron\n",
    "    signal_2ndPass = reco_2ndPass[camera_index][np.where(t_2ndPass>0)]\n",
    "    noise_2ndPass = reco_2ndPass[camera_index][np.where(t_2ndPass==0)]\n",
    "    \n",
    "    # Plot 1st-Pass\n",
    "    \n",
    "    hist_1, xbins_1 = np.histogram(np.log10(reco_1stPass[camera_index]), bins=nbins, range=xrange)\n",
    "    plt.semilogy(xbins_1[:-1], hist_1[::-1].cumsum()[::-1]/tot_entries, drawstyle=\"steps-post\",alpha=0.7, label=\"1st-pass signal + noise\", color='blue')\n",
    "    \n",
    "    # Plot 2nd-Pass\n",
    "    \n",
    "    hist_2, xbins_2 = np.histogram(np.log10(reco_2ndPass[camera_index]), bins=nbins, range=xrange)\n",
    "    plt.semilogy(xbins_2[:-1], hist_2[::-1].cumsum()[::-1]/tot_entries, drawstyle=\"steps-post\",alpha=0.7, label=\"2nd-pass signal + noise\", color='orange')\n",
    "\n",
    "    # common style options\n",
    "    plt.xlim(xrange)\n",
    "    plt.minorticks_on()\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    \n",
    "    # Print info about threshold cuts\n",
    "    # This is information related to 2nd pass (the one that ends up into image cleaning)\n",
    "    \n",
    "    # This is the cut in (biased) photoelectrons that rejects 99.7% of the \"noise\"\n",
    "    cut = np.quantile(noise_2ndPass, 0.997)\n",
    "    core_thresholds.append(cut)\n",
    "    signal_saved = percentileofscore(signal_2ndPass, cut)\n",
    "    plt.vlines(np.log10(cut), ymin=1.e-7, ymax=1, color='orange', linestyle=\"--\", label=f\"{cut:.2f} (biased) photoelectrons\")\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    print(f\"{cameras[camera_index]}: cutting at ~{cut:.5f} (biased) photoelectrons rejects 99.7% of the noise and saves {signal_saved:.1f}% of the signal\")\n",
    "\n",
    "    fig.savefig(f\"./plots_calibration/singlePixelSpectrum_{cameras[camera_index]}_protopipe_{config}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get optimized image cleaning thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimized BIASED image cleaning thresholds for:\")\n",
    "for camera_index in range(len(cameras)):\n",
    "    optimized_core_threshold = core_thresholds[camera_index]\n",
    "    optimized_boundary_threshold = optimized_core_threshold/2.\n",
    "    print(f\" - {cameras[camera_index]}: ({optimized_core_threshold:.2f},{optimized_boundary_threshold:.2f})\"\n",
    "          f\"--> ({int(round(optimized_core_threshold))}, {int(round(optimized_boundary_threshold))})\")\n",
    "\n",
    "print(\"\\nWARNING: since the pipeline doesn't know about the residual bias calculated before,\")\n",
    "print(\"you need to use the BIASED units to setup the image cleaning\")\n",
    "print(\"(i.e. the values to be put in the analysis configuration file of protopipe)\\n\")\n",
    "    \n",
    "print(\"Optimized UNBIASED image cleaning thresholds for:\")\n",
    "for camera_index in range(len(cameras)):\n",
    "    optimized_core_threshold = core_thresholds[camera_index] * corr[camera_index]\n",
    "    optimized_boundary_threshold = optimized_core_threshold/2.\n",
    "    print(f\" - {cameras[camera_index]}: ({optimized_core_threshold:.2f},{optimized_boundary_threshold:.2f})\"\n",
    "          f\"--> ({int(round(optimized_core_threshold))}, {int(round(optimized_boundary_threshold))})\")\n",
    "    \n",
    "print(\"\\nIf the pipeline corrected perfectly everything, you would expect the bias to be almost 0\")\n",
    "print(\"so the previous 2 sets of values should be very similar in that case.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
